{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DSCI552_HW7_Ruihao_Wang_9867439484.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "50JgYVxkr3w0"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDxp4i1ECoB0",
        "outputId": "dda96296-24e8-42b0-f408-9c0fc5dd4413"
      },
      "source": [
        "print(\"Num GPUs Available: \", \n",
        "      len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciz35pPPlyvV",
        "outputId": "9e3c16e4-410e-4db0-d58a-f64df384f456"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XTN2q3OnDkO"
      },
      "source": [
        "drive_nb_dir = '/content/drive/My Drive/Colab_Notebooks'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OgFX9NQ5pB0"
      },
      "source": [
        "# 1. Generative Models for Text\n",
        "\n",
        "### 1.(c)-i Concatenate text files to create corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx9k_eShyFvF"
      },
      "source": [
        "def createCorpus(data_dir):\n",
        "  print(data_dir)\n",
        "  corpus = []\n",
        "  for root, _, files in os.walk(data_dir):\n",
        "    for f in files:\n",
        "      with open(root + f, encoding='ascii', errors='ignore') as book:\n",
        "        cur_corpus = book.read().lower()\n",
        "        corpus.append(cur_corpus)\n",
        "      print('Read text {}, string length {}'.format(f, len(corpus[-1])))\n",
        "  corpus = sorted(corpus, key=lambda x : len(x))\n",
        "  return corpus"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbwBNEpyyF9Q",
        "outputId": "d83717c3-e82b-4ad1-9449-46e63bc10f37"
      },
      "source": [
        "concatCorpus = createCorpus(drive_nb_dir + '/data/books/')\n",
        "print([len(book) for book in concatCorpus])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab_Notebooks/data/books/\n",
            "Read text TAM.txt, string length 514652\n",
            "Read text OKEWFSMP.txt, string length 405741\n",
            "Read text TAMatter.txt, string length 766542\n",
            "Read text THWP.txt, string length 2005566\n",
            "Read text TPP.txt, string length 244306\n",
            "Read text AIIMAT.txt, string length 746219\n",
            "Read text MLOE.txt, string length 412226\n",
            "[244306, 405741, 412226, 514652, 746219, 766542, 2005566]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ0W-8DF6GFE"
      },
      "source": [
        "### 1.(c)-ii Use char-level representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6m0J0TU5kAk"
      },
      "source": [
        "def charRepresent(corpus, num_books):\n",
        "  chars = set([])\n",
        "  for book in corpus[:num_books]:\n",
        "    cur = list(set(book))\n",
        "    chars.update(cur)\n",
        "  chars = sorted(list(chars))\n",
        "  char2int = dict((c, i) for i, c in enumerate(chars))\n",
        "  int2char = dict((i, c) for i, c in enumerate(chars))\n",
        "  return char2int, int2char"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtJX8CSq-axZ",
        "outputId": "07d70e43-a7f8-4162-b4ce-2a0a157636bd"
      },
      "source": [
        "char2int, int2char = charRepresent(concatCorpus, 5)\n",
        "print(char2int)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '<': 29, '=': 30, '>': 31, '?': 32, '[': 33, '\\\\': 34, ']': 35, '^': 36, '_': 37, 'a': 38, 'b': 39, 'c': 40, 'd': 41, 'e': 42, 'f': 43, 'g': 44, 'h': 45, 'i': 46, 'j': 47, 'k': 48, 'l': 49, 'm': 50, 'n': 51, 'o': 52, 'p': 53, 'q': 54, 'r': 55, 's': 56, 't': 57, 'u': 58, 'v': 59, 'w': 60, 'x': 61, 'y': 62, 'z': 63, '{': 64, '|': 65, '}': 66, '~': 67}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHhZu2mVRvHj"
      },
      "source": [
        "### 1.(c)-iv Window the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VakFqZ_Mrkb"
      },
      "source": [
        "def windowCorpus(corpus, win_size, char2int):\n",
        "    input = []\n",
        "    output = []\n",
        "    for w in range(0, len(corpus)-win_size+1, 1):\n",
        "        seqIn = corpus[w : w + win_size - 1]\n",
        "        seqOut = corpus[w + win_size - 1]\n",
        "        #print(seqIn)\n",
        "        #print(seqOut)\n",
        "        input.append([char2int[c] for c in seqIn])\n",
        "        output.append(char2int[seqOut])\n",
        "    #print(len(output))\n",
        "    return input, output\n",
        "\n",
        "def dataGenerate(corpus, num_books):\n",
        "  win_size = 100\n",
        "  inSeq, outChar = [], []\n",
        "  for book in corpus[:num_books]:\n",
        "    cur_in, cur_out = windowCorpus(book, win_size, char2int)\n",
        "    inSeq.extend(cur_in)\n",
        "    outChar.extend(cur_out)\n",
        "  return inSeq, outChar"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7sqN5MmMrnU",
        "outputId": "1e66f4a6-4683-457c-96ba-e4db7cc64087"
      },
      "source": [
        "inSeq, outChar = dataGenerate(concatCorpus, 5)\n",
        "print(len(inSeq))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2322649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3UQAh_TUTay"
      },
      "source": [
        "### 1.(v) One-hot code the output and normalize input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xFnZMZ7Mrrl",
        "outputId": "dd0b4c64-57d0-4e58-f840-96e48ce79860"
      },
      "source": [
        "# reshape\n",
        "lstm_input = np.reshape(inSeq, (len(inSeq), 100 - 1, 1))\n",
        "print(lstm_input.shape)\n",
        "# normalize\n",
        "lstm_input = lstm_input / float(len(char2int))\n",
        "#print(lstm_input[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2322649, 99, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS1G7BtyVAEP",
        "outputId": "5a321ad6-af11-4c31-d37a-aad3a24870ef"
      },
      "source": [
        "lstm_output = np_utils.to_categorical(outChar)\n",
        "print(lstm_output.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2322649, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwO_kl_rVvzi"
      },
      "source": [
        "### 1.(c)-vi~x Build single layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWpACSItVupx",
        "outputId": "c88c8fff-0867-41bb-c0da-d3efd4734253"
      },
      "source": [
        "# build LSTM model\n",
        "LSTMmodel = Sequential()\n",
        "#len(char2int)\n",
        "LSTMmodel.add(LSTM(256,\n",
        "                   input_shape=(lstm_input.shape[1], lstm_input.shape[2])))\n",
        "LSTMmodel.add(Dropout(0.2))\n",
        "LSTMmodel.add(Dense(lstm_output.shape[1], activation='softmax'))\n",
        "print(LSTMmodel.summary())\n",
        "\n",
        "LSTMmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "filepath = drive_nb_dir + \"./LSTMweights/weights-improvement-{epoch:02d}-{loss:.2f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 256)               264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 68)                17476     \n",
            "=================================================================\n",
            "Total params: 281,668\n",
            "Trainable params: 281,668\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCrrm_cVVvNS",
        "outputId": "97c873db-1013-4feb-8a31-7738ec6ac3a4"
      },
      "source": [
        "# fit the model\n",
        "LSTMmodel.fit(lstm_input, lstm_output, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 2.6262\n",
            "Epoch 00001: loss improved from inf to 2.62615, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-01-2.63-bigger.hdf5\n",
            "18146/18146 [==============================] - 610s 34ms/step - loss: 2.6262\n",
            "Epoch 2/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 2.2632\n",
            "Epoch 00002: loss improved from 2.62615 to 2.26316, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-02-2.26-bigger.hdf5\n",
            "18146/18146 [==============================] - 613s 34ms/step - loss: 2.2632\n",
            "Epoch 3/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 2.1029\n",
            "Epoch 00003: loss improved from 2.26316 to 2.10294, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-03-2.10-bigger.hdf5\n",
            "18146/18146 [==============================] - 611s 34ms/step - loss: 2.1029\n",
            "Epoch 4/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 2.2588\n",
            "Epoch 00004: loss did not improve from 2.10294\n",
            "18146/18146 [==============================] - 609s 34ms/step - loss: 2.2588\n",
            "Epoch 5/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 2.5574\n",
            "Epoch 00005: loss did not improve from 2.10294\n",
            "18146/18146 [==============================] - 613s 34ms/step - loss: 2.5574\n",
            "Epoch 6/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 2.2813\n",
            "Epoch 00006: loss did not improve from 2.10294\n",
            "18146/18146 [==============================] - 612s 34ms/step - loss: 2.2813\n",
            "Epoch 7/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 2.0657\n",
            "Epoch 00007: loss improved from 2.10294 to 2.06570, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-07-2.07-bigger.hdf5\n",
            "18146/18146 [==============================] - 610s 34ms/step - loss: 2.0657\n",
            "Epoch 8/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.9538\n",
            "Epoch 00008: loss improved from 2.06570 to 1.95381, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-08-1.95-bigger.hdf5\n",
            "18146/18146 [==============================] - 608s 34ms/step - loss: 1.9538\n",
            "Epoch 9/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.8842\n",
            "Epoch 00009: loss improved from 1.95381 to 1.88416, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-09-1.88-bigger.hdf5\n",
            "18146/18146 [==============================] - 609s 34ms/step - loss: 1.8842\n",
            "Epoch 10/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.8394\n",
            "Epoch 00010: loss improved from 1.88416 to 1.83938, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-10-1.84-bigger.hdf5\n",
            "18146/18146 [==============================] - 606s 33ms/step - loss: 1.8394\n",
            "Epoch 11/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.8053\n",
            "Epoch 00011: loss improved from 1.83938 to 1.80527, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-11-1.81-bigger.hdf5\n",
            "18146/18146 [==============================] - 615s 34ms/step - loss: 1.8053\n",
            "Epoch 12/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.7758\n",
            "Epoch 00012: loss improved from 1.80527 to 1.77577, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-12-1.78-bigger.hdf5\n",
            "18146/18146 [==============================] - 611s 34ms/step - loss: 1.7758\n",
            "Epoch 13/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.7526\n",
            "Epoch 00013: loss improved from 1.77577 to 1.75259, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-13-1.75-bigger.hdf5\n",
            "18146/18146 [==============================] - 607s 33ms/step - loss: 1.7526\n",
            "Epoch 14/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.7342\n",
            "Epoch 00014: loss improved from 1.75259 to 1.73425, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-14-1.73-bigger.hdf5\n",
            "18146/18146 [==============================] - 608s 33ms/step - loss: 1.7343\n",
            "Epoch 15/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.7170\n",
            "Epoch 00015: loss improved from 1.73425 to 1.71696, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-15-1.72-bigger.hdf5\n",
            "18146/18146 [==============================] - 607s 33ms/step - loss: 1.7170\n",
            "Epoch 16/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.7031\n",
            "Epoch 00016: loss improved from 1.71696 to 1.70310, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-16-1.70-bigger.hdf5\n",
            "18146/18146 [==============================] - 607s 33ms/step - loss: 1.7031\n",
            "Epoch 17/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.6903\n",
            "Epoch 00017: loss improved from 1.70310 to 1.69031, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-17-1.69-bigger.hdf5\n",
            "18146/18146 [==============================] - 612s 34ms/step - loss: 1.6903\n",
            "Epoch 18/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.6794\n",
            "Epoch 00018: loss improved from 1.69031 to 1.67938, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-18-1.68-bigger.hdf5\n",
            "18146/18146 [==============================] - 611s 34ms/step - loss: 1.6794\n",
            "Epoch 19/20\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.6687\n",
            "Epoch 00019: loss improved from 1.67938 to 1.66869, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-19-1.67-bigger.hdf5\n",
            "18146/18146 [==============================] - 609s 34ms/step - loss: 1.6687\n",
            "Epoch 20/20\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.7449\n",
            "Epoch 00020: loss did not improve from 1.66869\n",
            "18146/18146 [==============================] - 608s 34ms/step - loss: 1.7449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5106a3aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofs91dvYdDIy"
      },
      "source": [
        "### 1.(c)-vi Use the network with the best weights to generate 1000 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jYtQ8rknjQJ",
        "outputId": "3a984896-93b4-4a72-da8a-d08976a4b840"
      },
      "source": [
        "init = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
        "\n",
        "write = [char2int[c] for c in init[-99:].lower()]\n",
        "\n",
        "for i in range(1000):\n",
        "  # convert to numpy array and normalize it\n",
        "  seq = np.reshape(write, (1, len(write), 1))\n",
        "  seq = seq / float(len(char2int))\n",
        "  # predict the next character\n",
        "  predictChar = LSTMmodel.predict(seq, verbose=0)\n",
        "  predictIdx = np.argmax(predictChar)\n",
        "  init += int2char[predictIdx]\n",
        "  # make new input sequence\n",
        "  write.append(predictIdx)\n",
        "  write = write[1:len(write)]\n",
        "\n",
        "print(init)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object. the soace of the soace of the soace ase not the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the soace of the so\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjNRq_m0k1K9",
        "outputId": "4711f92f-a6c2-43a4-9b6a-373cdd27feaa"
      },
      "source": [
        "# fit the model for 10 epoch more\n",
        "LSTMmodel.fit(lstm_input, lstm_output, epochs=10, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.8942\n",
            "Epoch 00001: loss did not improve from 1.66869\n",
            "18146/18146 [==============================] - 610s 34ms/step - loss: 1.8942\n",
            "Epoch 2/10\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.6922\n",
            "Epoch 00002: loss did not improve from 1.66869\n",
            "18146/18146 [==============================] - 610s 34ms/step - loss: 1.6922\n",
            "Epoch 3/10\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.6611\n",
            "Epoch 00003: loss improved from 1.66869 to 1.66108, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-03-1.66-bigger.hdf5\n",
            "18146/18146 [==============================] - 614s 34ms/step - loss: 1.6611\n",
            "Epoch 4/10\n",
            "18145/18146 [============================>.] - ETA: 0s - loss: 1.7563\n",
            "Epoch 00004: loss did not improve from 1.66108\n",
            "18146/18146 [==============================] - 607s 33ms/step - loss: 1.7563\n",
            "Epoch 5/10\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.8051\n",
            "Epoch 00005: loss did not improve from 1.66108\n",
            "18146/18146 [==============================] - 607s 33ms/step - loss: 1.8051\n",
            "Epoch 6/10\n",
            "18146/18146 [==============================] - ETA: 0s - loss: 1.6516\n",
            "Epoch 00006: loss improved from 1.66108 to 1.65162, saving model to /content/drive/My Drive/Colab_Notebooks./LSTMweights/weights-improvement-06-1.65-bigger.hdf5\n",
            "18146/18146 [==============================] - 612s 34ms/step - loss: 1.6516\n",
            "Epoch 7/10\n",
            " 9374/18146 [==============>...............] - ETA: 4:53 - loss: 1.6435Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wxjHqFTnkog",
        "outputId": "cb44af6d-aae5-477e-b89c-a3efc1a5126e"
      },
      "source": [
        "init = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
        "\n",
        "write = [char2int[c] for c in init[-99:].lower()]\n",
        "\n",
        "for i in range(1000):\n",
        "  # convert to numpy array and normalize it\n",
        "  seq = np.reshape(write, (1, len(write), 1))\n",
        "  seq = seq / float(len(char2int))\n",
        "  # predict the next character\n",
        "  predictChar = LSTMmodel.predict(seq, verbose=0)\n",
        "  predictIdx = np.argmax(predictChar)\n",
        "  init += int2char[predictIdx]\n",
        "  # make new input sequence\n",
        "  write.append(predictIdx)\n",
        "  write = write[1:len(write)]\n",
        "\n",
        "print(init)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object. the sraae of the srace of the srace of the srace of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace of the sraae of the srace o\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}